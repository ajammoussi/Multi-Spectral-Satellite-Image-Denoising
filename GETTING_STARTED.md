# üöÄ Getting Started - Multi-Spectral Satellite Image Denoising

## ‚úÖ Project Status: Production-Ready

This project implements multi-spectral satellite image restoration using Transfer Learning with SatMAE on TRUE 13-band Sentinel-2 imagery. Optimized for NVIDIA RTX 4050 (6GB VRAM).

---

## üìã Quick Start Options

### Option A: Test Pipeline First (5 minutes)
```bash
# Quick validation
jupyter notebook notebooks/00_quick_setup_test.ipynb
```

### Option B: Start Training Immediately  
```bash
python scripts/train.py --config configs/base.yaml
```

### Option C: Experiment with Different Noise Levels
```bash
# Low noise (easier, faster convergence)
python scripts/train.py --config configs/experiments/low_noise.yaml

# Medium noise (balanced)
python scripts/train.py --config configs/experiments/medium_noise.yaml

# High noise (challenging)
python scripts/train.py --config configs/experiments/high_noise.yaml
```

---

## üõ†Ô∏è Installation

### Option 1: Conda Environment (Recommended)
```bash
# Create environment
conda create -n satmae python=3.10
conda activate satmae

# Install PyTorch with CUDA support
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# Install dependencies
pip install -r requirements.txt

# Optional: Install rasterio for .tif support
conda install -c conda-forge rasterio
```

### Option 2: pip Only
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

---

## üìä Dataset & Weights

The project uses TRUE 13-band multi-spectral Sentinel-2 data:

**Dataset**: EuroSAT Multi-Spectral
- 13 spectral bands (B01-B12, B8A)
- 27,000 images (10 land-use classes)
- Native .tif format (not RGB)
- ~2GB download

**Pre-trained Weights**: SatMAE ViT-Base
- Trained on Sentinel-2 imagery
- 330MB download
- Enables transfer learning

### Automatic Download:
```bash
# Downloads both dataset and weights
jupyter notebook notebooks/00_quick_setup_test.ipynb
# OR
python -c "from src.utils import setup_project_data; setup_project_data()"
```

### Manual Download:
1. **Dataset**: Download from [EuroSAT GitHub](https://github.com/phelber/EuroSAT) and place in `data/EuroSAT_MS/`
2. **Weights**: Download SatMAE weights from [SustainLab](https://github.com/sustainlab-group/SatMAE) and place in `weights/satmae_pretrain.pth`

---

## üéØ 2-Day Implementation Guide

### Day 1: Setup & Validation (6-8 hours)

#### Step 1: Environment Setup (1-2 hours)
```bash
conda create -n satmae python=3.10
conda activate satmae
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
```

#### Step 2: Data Download & Verification (1-2 hours)
```bash
jupyter notebook notebooks/00_quick_setup_test.ipynb
```
Expected output:
- ‚úì Dataset downloaded: 27,000 images
- ‚úì Weights downloaded: ~330MB
- ‚úì Sample visualization working

#### Step 3: Model Verification (1-2 hours)
```python
import torch
from src.models import SatMAERestoration
from src.utils import load_config

config = load_config('configs/base.yaml')
model = SatMAERestoration(config)

# Test forward pass
dummy_input = torch.randn(2, 13, 192, 192)
output = model(dummy_input)
print(f"‚úì Forward pass successful: {output.shape}")
```

#### Step 4: VRAM Profiling (1-2 hours)
```python
if torch.cuda.is_available():
    model = model.cuda()
    memory_stats = model.profile_memory(batch_size=8)
    print(f"Peak VRAM: {memory_stats['peak_vram_gb']:.2f} GB")
```
Expected: ~3GB (safe for RTX 4050)

---

### Day 2: Training & Evaluation (6-8 hours)

#### Step 5: Quick Training Test (1-2 hours)
```bash
# 10 epochs sanity check
python scripts/train.py --config configs/experiments/quick_test.yaml
```
Expected:
- No OOM errors
- Loss decreasing
- VRAM ~3GB

#### Step 6: Full Training (4-6 hours)
```bash
# Full 100 epochs
python scripts/train.py --config configs/base.yaml

# Monitor with TensorBoard (optional)
tensorboard --logdir outputs/logs
```

#### Step 7: Evaluation & Export (30 minutes)
```bash
# Evaluate best model
python scripts/evaluate.py --checkpoint outputs/checkpoints/stage_b/best_model_psnr.pth

# Or use notebook
jupyter notebook notebooks/03_evaluation.ipynb
```

---

## üìà Expected Results

After training (100 epochs, ~6 hours on RTX 4050):

| Metric | Expected Range | Achieved |
|--------|---------------|----------|
| **PSNR** | 30-35 dB | **41.5 dB** ‚úÖ |
| **SSIM** | 0.90-0.95 | **0.988** ‚úÖ |
| **SAM** | < 5¬∞ | **1.86¬∞** ‚úÖ |
| **Inference Speed** | 50-100ms | **10ms** (ONNX) ‚úÖ |
| **VRAM Usage** | < 6GB | **~3GB** ‚úÖ |

---

## üìö Learning Paths

### Path 1: Quick Start (For Impatient Users)
1. Run `notebooks/00_quick_setup_test.ipynb` (5 min)
2. Run `python scripts/train.py --config configs/base.yaml` (6 hrs)
3. Run `notebooks/03_evaluation.ipynb` (30 min)
4. Done!

### Path 2: Step-by-Step (For Learners)
1. `notebooks/00_quick_setup_test.ipynb` - Setup & data verification
2. `notebooks/02_training.ipynb` - Interactive training with visualization
3. `notebooks/03_evaluation.ipynb` - Comprehensive evaluation & ONNX export
4. Understand everything!

### Path 3: Experimentation (For Researchers)
1. Train multiple models with different noise configurations
2. Compare results across metrics
3. Fine-tune hyperparameters in `configs/experiments/`
4. Analyze spectral reconstruction quality

---

## üóÇÔ∏è Project Structure

```
Multi-Spectral-Satellite-Image-Denoising/
‚îú‚îÄ‚îÄ configs/              # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ base.yaml        # Base configuration
‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml  # ONNX export settings
‚îÇ   ‚îî‚îÄ‚îÄ experiments/     # Experiment configs
‚îú‚îÄ‚îÄ data/                # Dataset storage
‚îÇ   ‚îî‚îÄ‚îÄ EuroSAT_MS/     # 13-band multi-spectral data
‚îú‚îÄ‚îÄ notebooks/           # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ 00_quick_setup_test.ipynb  # Setup & validation
‚îÇ   ‚îú‚îÄ‚îÄ 02_training.ipynb          # Interactive training
‚îÇ   ‚îî‚îÄ‚îÄ 03_evaluation.ipynb        # Evaluation & export
‚îú‚îÄ‚îÄ outputs/             # Training outputs
‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/    # Model checkpoints
‚îÇ   ‚îú‚îÄ‚îÄ logs/           # Training logs
‚îÇ   ‚îî‚îÄ‚îÄ onnx/           # Exported models
‚îú‚îÄ‚îÄ scripts/             # Command-line scripts
‚îÇ   ‚îú‚îÄ‚îÄ train.py        # Training script
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py     # Evaluation script
‚îÇ   ‚îî‚îÄ‚îÄ export.py       # ONNX export script
‚îú‚îÄ‚îÄ src/                 # Source code
‚îÇ   ‚îú‚îÄ‚îÄ data/           # Dataset & transforms
‚îÇ   ‚îú‚îÄ‚îÄ models/         # Architecture
‚îÇ   ‚îú‚îÄ‚îÄ training/       # Training loop & metrics
‚îÇ   ‚îú‚îÄ‚îÄ deployment/     # ONNX export & inference
‚îÇ   ‚îî‚îÄ‚îÄ utils/          # Helpers & utilities
‚îî‚îÄ‚îÄ weights/             # Pre-trained weights
    ‚îî‚îÄ‚îÄ satmae_pretrain.pth
```

---

## üîß Configuration

### Key Configuration Files:

**`configs/base.yaml`** - Main configuration
- Image size: 192√ó192 (matches checkpoint)
- Batch size: 8 (micro) √ó 8 (accumulation) = 64 effective
- Mixed precision: Enabled (FP16)
- Gradient checkpointing: Enabled

**`configs/experiments/`** - Noise level experiments
- `low_noise.yaml` - Easier, faster convergence
- `medium_noise.yaml` - Balanced challenge
- `high_noise.yaml` - Stress test

### Customize Training:
```yaml
# configs/my_experiment.yaml
training:
  epochs: 150
  effective_batch_size: 128
  optimizer:
    lr: 5e-5
noise:
  gaussian_sigma: 0.020
```

Run with:
```bash
python scripts/train.py --config configs/my_experiment.yaml
```

---

## ‚ö†Ô∏è Common Issues & Solutions

### Issue: OOM Error (Out of Memory)
**Solution**: Reduce `micro_batch_size` in config from 8 to 4

### Issue: Slow Training
**Solution**: 
- Enable mixed precision: `mixed_precision: true`
- Reduce `num_workers` if CPU bottleneck

### Issue: Poor Results
**Solution**:
- Train longer (100+ epochs)
- Try lower noise config first
- Check data normalization

### Issue: Import Error for `rasterio`
**Solution**: rasterio is optional
```bash
# Install if needed
conda install -c conda-forge rasterio
# OR code will fallback to PIL
```

---

## üöÄ Next Steps

After completing training:

1. **Deploy with ONNX**: Faster inference (~1.16x speedup √ºber PyTorch)
   ```bash
   python scripts/export.py --checkpoint outputs/checkpoints/best_model_psnr.pth
   ```

2. **Optimize Further**:
   - INT8 quantization for edge devices
   - TensorRT for NVIDIA GPUs
   - Model pruning

3. Fine-tune on domain-specific data

4. **Integrate into pipeline**:
   ```python
   from src.deployment import ONNXInferenceSession
   
   session = ONNXInferenceSession('outputs/onnx/satmae_restoration.onnx')
   restored = session.predict(noisy_image)
   ```

---

## üìû Support & Documentation

- **README.md** - Full architecture & implementation details
- **Notebooks** - Interactive tutorials with visualizations
- **configs/** - Template configurations for experiments

---

## ‚úÖ System Requirements

**Minimum**:
- GPU: NVIDIA RTX 4050 (6GB VRAM) or equivalent
- RAM: 16GB
- Storage: 10GB free space
- Python: 3.10+
- CUDA: 11.8+

**Recommended**:
- GPU: RTX 4060+ (8GB+ VRAM)
- RAM: 32GB
- SSD storage
- CUDA: 12.0+

---

**Ready to start? Run:**
```bash
jupyter notebook notebooks/00_quick_setup_test.ipynb
```

Good luck! üéâ
